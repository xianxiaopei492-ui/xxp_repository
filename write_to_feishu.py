import pymysql
import requests
import time
import json
import decimal
from datetime import datetime, date
from decimal import Decimal

# ================== é…ç½®éƒ¨åˆ† ==================
APP_ID = "cli_a9bc132c7af81bc7"
APP_SECRET = "0xpxP8mp9Iu5kpymCGQ5FeAujRhAYAfB"
APP_Token = "NYd4bZZ8vagln2szwWec5gbhnoh"  # app_token
TABLE_ID = "tblPr0mGcW0iXlCh"  # table_id

MYSQL_CONFIG = {
    "host": "localhost",
    "user": "root",
    "password": "d15c76a0875e73c0",
    "database": "lingxing_orders",
    "charset": "utf8mb4"
}

MYSQL_TABLE = "orders_merge"

# ç›´æ¥ä½¿ç”¨è‹±æ–‡å­—æ®µååˆ—è¡¨
FIELD_NAMES = [
    "global_order_no", "reference_no", "store_id", "order_from_name",
    "delivery_type", "split_type", "order_status", "global_purchase_time",
    "global_payment_time", "global_review_time", "global_distribution_time",
    "global_print_time", "global_mark_time", "global_delivery_time",
    "amount_currency", "global_latest_ship_time", "global_cancel_time",
    "update_time", "order_tag", "pending_order_tag", "exception_order_tag",
    "wid", "warehouse_name", "original_global_order_no", "supplier_id",
    "is_delete", "order_custom_fields", "global_create_time",
    "logistics_type_id", "logistics_type_name", "logistics_provider_id",
    "logistics_provider_name", "actual_carrier", "waybill_no", "pre_weight",
    "pre_fee_weight", "pre_fee_weight_unit", "pre_pkg_length", "pre_pkg_height",
    "pre_pkg_width", "weight", "pkg_fee_weight", "pkg_fee_weight_unit",
    "pkg_length", "pkg_width", "pkg_height", "weight_unit", "pkg_size_unit",
    "cost_currency_code", "pre_cost_amount", "cost_amount", "logistics_time",
    "tracking_no", "mark_no", "global_item_no", "item_id", "platform_order_no",
    "order_item_no", "item_from_name", "msku", "local_sku", "product_no",
    "local_product_name", "is_bundled", "title", "variant_attr", "unit_price_amount",
    "item_price_amount", "quantity", "platform_status", "item_type", "stock_cost_amount",
    "wms_outbound_cost_amount", "stock_deduct_id", "stock_deduct_name", "cg_price_amount",
    "shipping_amount", "wms_shipping_price_amount", "customer_shipping_amount",
    "discount_amount", "customer_tip_amount", "tax_amount", "sales_revenue_amount",
    "transaction_fee_amount", "other_amount", "customized_url", "platform_subsidy_amount",
    "cod_amount", "gift_wrap_amount", "platform_tax_amount", "points_granted_amount",
    "other_fee", "delivery_time", "source_name", "data_json", "item_custom_fields"
]


# åŠ¨æ€å­—æ®µç±»å‹æ˜ å°„å‡½æ•°
def get_field_type(field_name):
    """æ ¹æ®å­—æ®µåç¡®å®šå­—æ®µç±»å‹"""
    # å¸¦_timeåç¼€çš„å­—æ®µä½¿ç”¨æ–‡æœ¬ç±»å‹ (1)
    if field_name.endswith('_time'):
        return 1

    # æ•°å­—ç±»å‹å­—æ®µå…³é”®è¯è¯†åˆ«
    num_keywords = ['amount', 'weight', 'price', 'cost', 'fee', 'quantity',
                    'number', 'count', 'total', 'sum', 'avg', 'average',
                    'max', 'min', 'rate', 'ratio', 'percent', 'percentage']

    for keyword in num_keywords:
        if keyword in field_name.lower():
            return 2  # æ•°å­—ç±»å‹

    # æ ‡è¯†å­—æ®µä½¿ç”¨æ–‡æœ¬ç±»å‹
    id_keywords = ['_id', '_no', 'id_', 'no_']
    for keyword in id_keywords:
        if keyword in field_name.lower():
            return 1  # æ–‡æœ¬ç±»å‹

    # å¸ƒå°”ç±»å‹å­—æ®µ
    bool_keywords = ['is_', 'has_', 'can_', 'enable', 'disable', 'active']
    for keyword in bool_keywords:
        if keyword in field_name.lower():
            return 1  # æ–‡æœ¬ç±»å‹ï¼ˆé£ä¹¦æ²¡æœ‰ä¸“é—¨çš„å¸ƒå°”ç±»å‹ï¼Œç”¨æ–‡æœ¬è¡¨ç¤ºï¼‰

    # é»˜è®¤ä½¿ç”¨æ–‡æœ¬ç±»å‹
    return 1


# ================== é£ä¹¦APIå·¥å…·å‡½æ•° ==================
def get_tenant_access_token():
    """è·å–è®¿é—®ä»¤ç‰Œ"""
    url = "https://open.feishu.cn/open-apis/auth/v3/tenant_access_token/internal"
    resp = requests.post(url, json={
        "app_id": APP_ID,
        "app_secret": APP_SECRET
    }).json()

    if resp.get("code") != 0:
        raise Exception(f"è·å–tokenå¤±è´¥: {resp}")

    return resp["tenant_access_token"]


def get_existing_fields(token):
    """è·å–è¡¨æ ¼ä¸­ç°æœ‰çš„å­—æ®µä¿¡æ¯ï¼ˆåŒ…å«ç±»å‹ï¼‰"""
    url = f"https://open.feishu.cn/open-apis/bitable/v1/apps/{APP_Token}/tables/{TABLE_ID}/fields"
    headers = {"Authorization": f"Bearer {token}"}

    try:
        response = requests.get(url, headers=headers)
        result = response.json()

        if result.get("code") == 0:
            fields = result.get("data", {}).get("items", [])
            field_info = {}
            for field in fields:
                field_name = field.get("field_name")
                field_type = field.get("type")
                field_info[field_name] = {
                    "type": field_type,
                    "ui_type": field.get("ui_type"),
                    "field_id": field.get("field_id")
                }
            print(f"âœ… è·å–åˆ°ç°æœ‰å­—æ®µ: {len(field_info)} ä¸ª")
            return field_info
        else:
            error_msg = result.get("msg", "æœªçŸ¥é”™è¯¯")
            error_code = result.get("code")
            print(f"âŒ è·å–å­—æ®µå¤±è´¥: {error_msg} (é”™è¯¯ç : {error_code})")
            return {}

    except Exception as e:
        print(f"âŒ è·å–å­—æ®µå¼‚å¸¸: {e}")
        return {}


def create_field(token, field_name, field_type=1):
    """åˆ›å»ºæ–°å­—æ®µ"""
    url = f"https://open.feishu.cn/open-apis/bitable/v1/apps/{APP_Token}/tables/{TABLE_ID}/fields"
    headers = {
        "Authorization": f"Bearer {token}",
        "Content-Type": "application/json"
    }

    # æ ¹æ®å­—æ®µç±»å‹è®¾ç½®ä¸åŒçš„å‚æ•°
    if field_type == 1:  # æ–‡æœ¬ç±»å‹
        payload = {
            "field_name": field_name,
            "type": 1
        }
    elif field_type == 2:  # æ•°å­—ç±»å‹
        payload = {
            "field_name": field_name,
            "type": 2,
            "property": {
                "formatter": "0.00",  # ä¿ç•™2ä½å°æ•°
                "precision": 2,
                "decimal_symbol": "."
            }
        }
    else:
        payload = {
            "field_name": field_name,
            "type": 1
        }

    try:
        print(f"æ­£åœ¨åˆ›å»ºå­—æ®µ: {field_name} (ç±»å‹: {field_type})")
        response = requests.post(url, headers=headers, json=payload, timeout=10)
        result = response.json()
        if result.get("code") == 0:
            print(f"âœ… æˆåŠŸåˆ›å»ºå­—æ®µ: {field_name} (ç±»å‹: {field_type})")
            return True
        else:
            error_msg = result.get("msg", "æœªçŸ¥é”™è¯¯")
            error_code = result.get("code")
            print(f"âŒ åˆ›å»ºå­—æ®µå¤±è´¥ [{field_name}]: {error_msg} (é”™è¯¯ç : {error_code})")

            # æ ¹æ®é”™è¯¯ç æä¾›å…·ä½“å»ºè®®
            if error_code == 1254040:
                print(f"ğŸ’¡ å»ºè®®: è¡¨æ ¼å¯èƒ½ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥ TABLE_ID æ˜¯å¦æ­£ç¡®")
            elif error_code == 99991400:
                print(f"ğŸ’¡ å»ºè®®: åº”ç”¨æƒé™ä¸è¶³ï¼Œè¯·æ£€æŸ¥åº”ç”¨æ˜¯å¦æœ‰å¤šç»´è¡¨æ ¼ç¼–è¾‘æƒé™")
            elif "date" in error_msg.lower():
                print(f"ğŸ’¡ å»ºè®®: æ—¥æœŸå­—æ®µé…ç½®å¯èƒ½æœ‰é—®é¢˜ï¼Œæ£€æŸ¥æ—¥æœŸæ ¼å¼")

            return False

    except Exception as e:
        print(f"âŒ åˆ›å»ºå­—æ®µå¼‚å¸¸ [{field_name}]: {e}")
        return False


def create_missing_fields(token):
    """åˆ›å»ºç¼ºå¤±çš„å­—æ®µ"""
    print("ğŸ” å¼€å§‹æ£€æŸ¥å¹¶åˆ›å»ºç¼ºå¤±å­—æ®µ...")

    # è·å–ç°æœ‰å­—æ®µ
    existing_fields = get_existing_fields(token)
    existing_field_names = list(existing_fields.keys())

    # éœ€è¦åˆ›å»ºçš„å­—æ®µï¼ˆç›´æ¥ä½¿ç”¨è‹±æ–‡å­—æ®µåï¼‰
    required_fields = FIELD_NAMES

    # æ‰¾å‡ºç¼ºå¤±çš„å­—æ®µ
    missing_fields = [field for field in required_fields if field not in existing_field_names]
    if not missing_fields:
        print("âœ… æ‰€æœ‰å­—æ®µå·²å­˜åœ¨ï¼Œæ— éœ€åˆ›å»º")
        return True

    print(f"ğŸ“‹ éœ€è¦åˆ›å»º {len(missing_fields)} ä¸ªç¼ºå¤±å­—æ®µ:")
    for field in missing_fields:
        print(f"   - {field}")

    # æ‰¹é‡åˆ›å»ºå­—æ®µ
    success_count = 0
    for field_name in missing_fields:
        # åŠ¨æ€ç¡®å®šå­—æ®µç±»å‹
        field_type = get_field_type(field_name)
        if create_field(token, field_name, field_type):
            success_count += 1
        time.sleep(0.5)

    print(f"ğŸ¯ å­—æ®µåˆ›å»ºå®Œæˆ: æˆåŠŸ {success_count}/{len(missing_fields)} ä¸ª")
    return success_count == len(missing_fields)


# ================== æ–°å¢åŠŸèƒ½ï¼šé‡å¤æ•°æ®æ£€æŸ¥ ==================
def get_existing_global_item_nos(token, max_records=10000):
    """
    è·å–é£ä¹¦å¤šç»´è¡¨æ ¼ä¸­å·²å­˜åœ¨çš„global_item_noå€¼
    ç”¨äºå»é‡æ£€æŸ¥
    """
    print("ğŸ” æ£€æŸ¥é£ä¹¦è¡¨æ ¼ä¸­å·²å­˜åœ¨çš„è®°å½•...")
    existing_items = set()
    page_token = None
    total_retrieved = 0

    # é£ä¹¦APIæ¯æ¬¡æœ€å¤šè¿”å›100æ¡è®°å½•ï¼Œéœ€è¦åˆ†é¡µè·å–
    while total_retrieved < max_records:
        url = f"https://open.feishu.cn/open-apis/bitable/v1/apps/{APP_Token}/tables/{TABLE_ID}/records"
        headers = {"Authorization": f"Bearer {token}"}

        params = {"page_size": 100}  # æ¯æ¬¡è·å–100æ¡
        if page_token:
            params["page_token"] = page_token

        try:
            response = requests.get(url, headers=headers, params=params, timeout=30)
            result = response.json()

            if result.get("code") == 0:
                records = result.get("data", {}).get("items", [])
                if not records:
                    break

                # æå–global_item_noå­—æ®µå€¼
                for record in records:
                    fields = record.get("fields", {})
                    global_item_no = fields.get("global_item_no")
                    if global_item_no:
                        existing_items.add(str(global_item_no))

                total_retrieved += len(records)
                print(f"âœ… å·²æ£€ç´¢ {total_retrieved} æ¡è®°å½•ï¼Œå‘ç° {len(existing_items)} ä¸ªå”¯ä¸€global_item_no")

                # æ£€æŸ¥æ˜¯å¦æœ‰ä¸‹ä¸€é¡µ
                page_token = result.get("data", {}).get("page_token")
                if not page_token:
                    break

                # é¿å…è¯·æ±‚è¿‡å¿«
                time.sleep(0.2)

            else:
                error_msg = result.get("msg", "æœªçŸ¥é”™è¯¯")
                error_code = result.get("code")
                print(f"âŒ è·å–è®°å½•å¤±è´¥: {error_msg} (é”™è¯¯ç : {error_code})")
                break

        except Exception as e:
            print(f"âŒ è·å–è®°å½•å¼‚å¸¸: {e}")
            break

    print(f"ğŸ¯ å»é‡æ£€æŸ¥å®Œæˆ: å…±å‘ç° {len(existing_items)} ä¸ªå·²å­˜åœ¨çš„global_item_no")
    return existing_items


def filter_duplicate_records(feishu_records, existing_global_item_nos):
    """
    è¿‡æ»¤æ‰global_item_noå·²å­˜åœ¨çš„è®°å½•
    """
    unique_records = []
    duplicate_count = 0

    for record in feishu_records:
        global_item_no = record.get("global_item_no")
        if global_item_no and str(global_item_no) in existing_global_item_nos:
            duplicate_count += 1
        else:
            unique_records.append(record)

    if duplicate_count > 0:
        print(f"ğŸ”„ è¿‡æ»¤æ‰ {duplicate_count} æ¡é‡å¤è®°å½•ï¼Œå‰©ä½™ {len(unique_records)} æ¡å”¯ä¸€è®°å½•")

    return unique_records


# ================== æ•°æ®è½¬æ¢å‡½æ•° ==================
class CustomJSONEncoder(json.JSONEncoder):
    """è‡ªå®šä¹‰JSONç¼–ç å™¨"""

    def default(self, obj):
        if isinstance(obj, (decimal.Decimal, Decimal)):
            return float(obj)
        elif isinstance(obj, (datetime, date)):
            return obj.isoformat()
        elif isinstance(obj, bytes):
            return str(obj, encoding='utf-8')
        else:
            return super(CustomJSONEncoder, self).default(obj)


def safe_json_dumps(data):
    """å®‰å…¨åºåˆ—åŒ–"""
    return json.dumps(data, cls=CustomJSONEncoder, ensure_ascii=False)


def convert_value_for_feishu(value, field_name=None):
    """å€¼ç±»å‹è½¬æ¢ï¼Œæ ¹æ®å­—æ®µç±»å‹å¤„ç† - å¢å¼ºè°ƒè¯•ç‰ˆ"""
    if value is None:
        print(f"âš ï¸  å­—æ®µ {field_name} çš„å€¼ä¸º None")
        return None

    # åŠ¨æ€è·å–å­—æ®µç±»å‹
    field_type = get_field_type(field_name) if field_name else 1

    # ç‰¹åˆ«ç›‘æ§æœ‰é—®é¢˜çš„å­—æ®µ
    debug_fields = ["cost_currency_code", "weight_unit","amount_currency","pre_fee_weight_unit","pkg_fee_weight_unit"]
    is_debug = field_name in debug_fields

    if is_debug:
        print(f"ğŸ” è°ƒè¯• {field_name}: åŸå§‹å€¼={value}, ç±»å‹={type(value)}, ç›®æ ‡å­—æ®µç±»å‹={field_type}")

    try:
        # æ•°å­—ç±»å‹å¤„ç†
        if field_type == 2:
            if isinstance(value, (decimal.Decimal, Decimal)):
                result = float(value)
            elif isinstance(value, (int, float)):
                result = value
            elif isinstance(value, str):
                try:
                    result = float(value.strip())
                except:
                    if is_debug:
                        print(f"âŒ {field_name} å­—ç¬¦ä¸²è½¬æ•°å­—å¤±è´¥: {value}")
                    return None
            else:
                if is_debug:
                    print(f"âŒ {field_name} ä¸æ”¯æŒçš„æ•°å­—ç±»å‹: {type(value)}")
                return None

        # æ–‡æœ¬ç±»å‹å¤„ç†
        else:
            if isinstance(value, (decimal.Decimal, Decimal)):
                result = str(value)
            elif isinstance(value, bytes):
                result = value.decode('utf-8', errors='ignore')
            elif value is None:
                result = ""
            else:
                result = str(value)

        if is_debug:
            print(f"âœ… {field_name} è½¬æ¢æˆåŠŸ: {value} -> {result}")

        return result

    except Exception as e:
        print(f"âŒ è½¬æ¢å€¼å¤±è´¥ [{field_name}]: {value} -> {e}")
        return None


# ================== å¢å¼ºé”™è¯¯æ£€æµ‹çš„æ‰¹é‡æ’å…¥å‡½æ•° ==================
def analyze_feishu_error(error_code, error_msg, batch_data_sample=None):
    """åˆ†æé£ä¹¦APIé”™è¯¯å¹¶è¿”å›å…·ä½“åŸå› å’Œå»ºè®®"""
    error_analysis = {
        "code": error_code,
        "message": error_msg,
        "possible_causes": [],
        "suggestions": []
    }

    # åŸºäºå¸¸è§é”™è¯¯ç çš„åˆ†æ [1,3](@ref)
    if error_code == 99991400:
        error_analysis["possible_causes"] = ["APP_IDæˆ–APP_SECRETé”™è¯¯", "åº”ç”¨æƒé™ä¸è¶³"]
        error_analysis["suggestions"] = [
            "æ£€æŸ¥APP_IDå’ŒAPP_SECRETæ˜¯å¦æ­£ç¡®",
            "åœ¨é£ä¹¦å¼€æ”¾å¹³å°ç¡®è®¤åº”ç”¨å·²å¼€é€šå¤šç»´è¡¨æ ¼ç›¸å…³æƒé™",
            "ç¡®è®¤åº”ç”¨å·²å‘å¸ƒç‰ˆæœ¬"
        ]
    elif error_code == 1254040:
        error_analysis["possible_causes"] = ["è¡¨æ ¼ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®"]
        error_analysis["suggestions"] = [
            "æ£€æŸ¥APP_Tokenå’ŒTABLE_IDæ˜¯å¦æ­£ç¡®",
            "ç¡®è®¤åº”ç”¨æœ‰è¯¥è¡¨æ ¼çš„è®¿é—®æƒé™",
            "åœ¨é£ä¹¦å¤šç»´è¡¨æ ¼ä¸­ç¡®è®¤è¡¨æ ¼å­˜åœ¨"
        ]
    elif error_code == 1254020 or "field" in error_msg.lower():
        error_analysis["possible_causes"] = ["å­—æ®µä¸å­˜åœ¨æˆ–å­—æ®µç±»å‹ä¸åŒ¹é…", "æ•°æ®æ ¼å¼é”™è¯¯"]
        error_analysis["suggestions"] = [
            "æ£€æŸ¥å­—æ®µåæ˜¯å¦æ­£ç¡®æ‹¼å†™",
            "ç¡®è®¤å­—æ®µå·²åˆ›å»ºä¸”ç±»å‹åŒ¹é…",
            "æ£€æŸ¥æ•°æ®å€¼æ˜¯å¦ç¬¦åˆå­—æ®µç±»å‹è¦æ±‚"
        ]
    elif "rate limit" in error_msg.lower() or "too many" in error_msg.lower():
        error_analysis["possible_causes"] = ["APIè°ƒç”¨é¢‘ç‡è¶…é™"]
        error_analysis["suggestions"] = [
            "å‡å°‘æ‰¹é‡å¤§å°æˆ–å¢åŠ è¯·æ±‚é—´éš”",
            "é£ä¹¦APIé¢‘ç‡é™åˆ¶ä¸º50æ¬¡/ç§’ï¼Œè¯·æ§åˆ¶è°ƒç”¨é¢‘ç‡ [6](@ref)"
        ]
    elif "date" in error_msg.lower() or "time" in error_msg.lower():
        error_analysis["possible_causes"] = ["æ—¥æœŸæ—¶é—´æ ¼å¼é”™è¯¯"]
        error_analysis["suggestions"] = [
            "ç¡®è®¤æ—¥æœŸæ—¶é—´å­—æ®µæ ¼å¼ä¸ºYYYY-MM-DD HH:mm:ss",
            "æ£€æŸ¥æ—¶é—´å€¼æ˜¯å¦åœ¨åˆç†èŒƒå›´å†…"
        ]
    elif "number" in error_msg.lower() or "numeric" in error_msg.lower():
        error_analysis["possible_causes"] = ["æ•°å­—æ ¼å¼é”™è¯¯"]
        error_analysis["suggestions"] = [
            "æ£€æŸ¥æ•°å­—å­—æ®µæ˜¯å¦åŒ…å«éæ•°å­—å­—ç¬¦",
            "ç¡®è®¤æ•°å­—å€¼åœ¨åˆç†èŒƒå›´å†…"
        ]
    else:
        error_analysis["possible_causes"] = ["æœªçŸ¥é”™è¯¯ï¼Œéœ€è¦è¿›ä¸€æ­¥æ’æŸ¥"]
        error_analysis["suggestions"] = [
            "æŸ¥çœ‹é£ä¹¦å®˜æ–¹APIæ–‡æ¡£é”™è¯¯ç è¯´æ˜",
            "æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œè®¤è¯ä¿¡æ¯",
            "å°è¯•å‡å°‘æ‰¹é‡å¤§å°é‡æ–°æ‰§è¡Œ"
        ]

    return error_analysis


def batch_insert_records(token, records, batch_size=500):  # æ”¹ä¸º500æ¡/æ‰¹
    """æ‰¹é‡æ’å…¥è®°å½• - å¢å¼ºé”™è¯¯æ£€æµ‹ç‰ˆ"""
    url = f"https://open.feishu.cn/open-apis/bitable/v1/apps/{APP_Token}/tables/{TABLE_ID}/records/batch_create"
    headers = {
        "Authorization": f"Bearer {token}",
        "Content-Type": "application/json"
    }

    total = len(records)
    success_count = 0

    if total == 0:
        print("âœ… æ²¡æœ‰éœ€è¦æ’å…¥çš„æ–°è®°å½•")
        return 0

    print(f"ğŸ“Š å¼€å§‹æ‰¹é‡æ’å…¥ {total} æ¡è®°å½•ï¼Œæ¯æ‰¹ {batch_size} æ¡")

    for i in range(0, total, batch_size):
        batch = records[i:i + batch_size]
        batch_num = i // batch_size + 1
        total_batches = (total + batch_size - 1) // batch_size

        print(f"\nğŸ“¦ å¤„ç†ç¬¬ {batch_num}/{total_batches} æ‰¹ï¼Œå…± {len(batch)} æ¡è®°å½•")

        # è½¬æ¢æ‰¹æ¬¡æ•°æ®
        batch_records = []
        for j, record in enumerate(batch):
            processed_fields = {}

            for key, value in record.items():
                processed_value = convert_value_for_feishu(value, key)
                if processed_value is not None:
                    processed_fields[key] = processed_value

            if processed_fields:
                batch_records.append({"fields": processed_fields})

        if not batch_records:
            print(f"âš ï¸  ç¬¬ {batch_num} æ‰¹æ²¡æœ‰æœ‰æ•ˆæ•°æ®")
            continue

        payload = {"records": batch_records}

        max_retries = 3
        for attempt in range(max_retries):
            try:
                json_payload = safe_json_dumps(payload)
                response = requests.post(url, headers=headers, data=json_payload.encode('utf-8'), timeout=60)
                result = response.json()

                if result.get("code") == 0:
                    batch_success = len(result.get("data", {}).get("records", []))
                    success_count += batch_success
                    print(f"âœ… ç¬¬ {batch_num} æ‰¹æˆåŠŸæ’å…¥: {batch_success} æ¡")

                    # æ˜¾ç¤ºè¿›åº¦
                    progress = min(i + len(batch), total)
                    print(f"ğŸ“ˆ æ€»ä½“è¿›åº¦: {progress}/{total} ({progress / total * 100:.1f}%)")
                    break  # æˆåŠŸï¼Œè·³å‡ºé‡è¯•å¾ªç¯

                else:
                    error_msg = result.get("msg", "æœªçŸ¥é”™è¯¯")
                    error_code = result.get("code")

                    # è¯¦ç»†é”™è¯¯åˆ†æ
                    error_analysis = analyze_feishu_error(error_code, error_msg,
                                                          batch_records[0] if batch_records else None)

                    print(f"âŒ ç¬¬ {batch_num} æ‰¹å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}):")
                    print(f"   é”™è¯¯ç : {error_code}")
                    print(f"   é”™è¯¯ä¿¡æ¯: {error_msg}")
                    print(f"   å¯èƒ½åŸå› : {', '.join(error_analysis['possible_causes'])}")
                    print(f"   å»ºè®®: {', '.join(error_analysis['suggestions'])}")

                    # å¦‚æœæ˜¯é¢‘ç‡é™åˆ¶é”™è¯¯ï¼Œç­‰å¾…åé‡è¯•
                    if "rate limit" in error_msg.lower() or "too many" in error_msg.lower():
                        wait_time = (attempt + 1) * 5  # æŒ‡æ•°é€€é¿ï¼š5, 10, 15ç§’
                        print(f"â³ é‡åˆ°é¢‘ç‡é™åˆ¶ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                        time.sleep(wait_time)
                        continue
                    else:
                        # éé‡è¯•é”™è¯¯ï¼Œç›´æ¥è·³å‡º
                        break

            except requests.exceptions.Timeout:
                print(f"âŒ ç¬¬ {batch_num} æ‰¹è¯·æ±‚è¶…æ—¶ (å°è¯• {attempt + 1}/{max_retries})")
                if attempt < max_retries - 1:
                    wait_time = (attempt + 1) * 3
                    print(f"â³ ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                    continue
                else:
                    print("âŒ é‡è¯•æ¬¡æ•°å·²ç”¨å°½ï¼Œè·³è¿‡æœ¬æ‰¹æ¬¡")
                    break

            except requests.exceptions.ConnectionError:
                print(f"âŒ ç¬¬ {batch_num} æ‰¹ç½‘ç»œè¿æ¥é”™è¯¯ (å°è¯• {attempt + 1}/{max_retries})")
                if attempt < max_retries - 1:
                    wait_time = (attempt + 1) * 5
                    print(f"â³ ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                    continue
                else:
                    print("âŒ é‡è¯•æ¬¡æ•°å·²ç”¨å°½ï¼Œè·³è¿‡æœ¬æ‰¹æ¬¡")
                    break

            except Exception as e:
                print(f"âŒ ç¬¬ {batch_num} æ‰¹å¼‚å¸¸: {e}")
                break

        # æ‰¹æ¬¡é—´å»¶è¿Ÿï¼Œé¿å…è§¦å‘é¢‘ç‡é™åˆ¶
        if i + batch_size < total:  # ä¸æ˜¯æœ€åä¸€æ‰¹
            delay_seconds = 2  # 500æ¡æ‰¹æ¬¡ç”¨2ç§’å»¶è¿Ÿ
            print(f"â³ ç­‰å¾… {delay_seconds} ç§’åå¤„ç†ä¸‹ä¸€æ‰¹...")
            time.sleep(delay_seconds)

    print(f"\nğŸ¯ æ‰¹é‡æ’å…¥å®Œæˆ: æˆåŠŸ {success_count}/{total} æ¡")
    return success_count


# ================== MySQLæ•°æ®è¯»å– ==================
def fetch_mysql_data(limit=None):
    """ä»MySQLè¯»å–æ•°æ®"""
    try:
        conn = pymysql.connect(**MYSQL_CONFIG)
        cursor = conn.cursor(pymysql.cursors.DictCursor)

        # åªé€‰æ‹©æŒ‡å®šçš„å­—æ®µ
        selected_fields = ','.join(FIELD_NAMES)
        sql = f"SELECT {selected_fields} FROM {MYSQL_TABLE}"

        if limit:
            sql += f" LIMIT {limit}"

        cursor.execute(sql)
        rows = cursor.fetchall()

        cursor.close()
        conn.close()
        return rows
    except Exception as e:
        print(f"âŒ è¯»å–MySQLæ•°æ®å¤±è´¥: {e}")
        return []


def convert_mysql_to_feishu_format(rows):
    """å°†MySQLæ•°æ®è½¬æ¢ä¸ºé£ä¹¦æ ¼å¼"""
    records = []

    for i, row in enumerate(rows):
        fields = {}
        for field_name in FIELD_NAMES:
            value = row.get(field_name)
            fields[field_name] = value
        records.append(fields)

    return records


# ================== ä¼˜åŒ–åçš„ä¸»æµç¨‹ ==================
def main():
    """ä¸»æ‰§è¡Œå‡½æ•° - å¢å¼ºé”™è¯¯æ£€æµ‹ç‰ˆ"""
    print("ğŸš€ å¼€å§‹é£ä¹¦å¤šç»´è¡¨æ ¼æ•°æ®åŒæ­¥æµç¨‹ï¼ˆå¢å¼ºé”™è¯¯æ£€æµ‹ç‰ˆï¼‰")
    print("=" * 60)
    print(f"æ•°æ®æº: {MYSQL_TABLE}")
    print(f"ç›®æ ‡è¡¨: {TABLE_ID}")
    print(f"æ‰¹é‡å¤§å°: 500æ¡/æ‰¹")  # æ›´æ–°ä¸º500æ¡
    print(f"å»é‡å­—æ®µ: global_item_no")

    try:
        # 1. è·å–è®¿é—®ä»¤ç‰Œ
        print("\n1. è·å–é£ä¹¦è®¿é—®ä»¤ç‰Œ...")
        token = get_tenant_access_token()
        print("âœ… Tokenè·å–æˆåŠŸ")

        # 2. åˆ›å»ºç¼ºå¤±å­—æ®µ
        print("\n2. æ£€æŸ¥å¹¶åˆ›å»ºç¼ºå¤±å­—æ®µ...")
        fields_created = create_missing_fields(token)

        # 3. è¯»å–MySQLæ•°æ®
        print("\n3. è¯»å–MySQLæ•°æ®...")
        mysql_rows = fetch_mysql_data()
        print(f"âœ… è¯»å–åˆ° {len(mysql_rows)} æ¡MySQLè®°å½•")

        if not mysql_rows:
            print("âŒ æœªè¯»å–åˆ°æ•°æ®ï¼Œæµç¨‹ç»“æŸ")
            return False

        # 4. æ•°æ®æ ¼å¼è½¬æ¢
        print("\n4. è½¬æ¢æ•°æ®æ ¼å¼...")
        feishu_records = convert_mysql_to_feishu_format(mysql_rows)
        print(f"âœ… æˆåŠŸè½¬æ¢ {len(feishu_records)} æ¡è®°å½•")

        # 5. å»é‡æ£€æŸ¥ï¼ˆæ–°å¢åŠŸèƒ½ï¼‰
        print("\n5. æ‰§è¡Œå»é‡æ£€æŸ¥...")
        existing_global_item_nos = get_existing_global_item_nos(token)
        unique_records = filter_duplicate_records(feishu_records, existing_global_item_nos)

        if not unique_records:
            print("ğŸ‰ æ‰€æœ‰æ•°æ®éƒ½å·²å­˜åœ¨ï¼Œæ— éœ€æ’å…¥æ–°è®°å½•")
            return True

        # 6. æ’å…¥æ•°æ®åˆ°é£ä¹¦
        print("\n6. æ’å…¥æ•°æ®åˆ°é£ä¹¦å¤šç»´è¡¨æ ¼...")
        success_count = batch_insert_records(token, unique_records, batch_size=500)  # æ”¹ä¸º500æ¡

        # 7. ç»“æœç»Ÿè®¡
        print("\n" + "=" * 60)
        if success_count > 0:
            print(f"ğŸ‰ æ•°æ®åŒæ­¥å®Œæˆ! æˆåŠŸæ’å…¥ {success_count}/{len(unique_records)} æ¡å”¯ä¸€è®°å½•")
            if len(feishu_records) > len(unique_records):
                duplicate_count = len(feishu_records) - len(unique_records)
                print(f"ğŸ” è‡ªåŠ¨è·³è¿‡ {duplicate_count} æ¡é‡å¤è®°å½•")
        else:
            print("âŒ æ•°æ®åŒæ­¥å¤±è´¥")

        return success_count > 0

    except Exception as e:
        print(f"\nğŸ’¥ æµç¨‹æ‰§è¡Œå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    main()