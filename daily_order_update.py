"""
è®¢å•çŠ¶æ€æ¯æ—¥è‡ªåŠ¨æ›´æ–°è„šæœ¬
åŠŸèƒ½ï¼šæ¯å¤©å®šæ—¶ä»é›¶æ˜Ÿå¹³å°APIè·å–æœ€æ–°è®¢å•çŠ¶æ€ï¼Œæ›´æ–°
æ–°å¢åŠŸèƒ½ï¼šæ¯æ—¥æ›´æ–°åº“å­˜ã€ä»“åº“ã€åº—é“ºä¿¡æ¯
"""

import os
import sys
import logging
import time
from datetime import datetime, timedelta
from dataoperator import DataOperator
from config import load_config_from_env
from main import LingXingAPI

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„ï¼Œç¡®ä¿å¯ä»¥å¯¼å…¥æ‚¨çš„æ¨¡å—
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# é…ç½®æ—¥å¿—ç³»ç»Ÿ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/var/log/daily_order_update.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)


class DailyOrderUpdater:
    """æ¯æ—¥è®¢å•çŠ¶æ€æ›´æ–°å™¨"""

    def __init__(self, app_id, app_secret, db_config):
        """
        åˆå§‹åŒ–æ›´æ–°å™¨

        Args:
            app_id: é›¶æ˜Ÿå¹³å°APP_ID
            app_secret: é›¶æ˜Ÿå¹³å°APP_SECRET
            db_config: æ•°æ®åº“è¿æ¥é…ç½®
        """
        self.api_client = LingXingAPI(app_id, app_secret)
        self.db_config = db_config
        self.data_operator = None

    def connect_database(self):
        """è¿æ¥æ•°æ®åº“"""
        try:
            self.data_operator = DataOperator(self.db_config)
            self.data_operator.connect_db()
            logger.info("æ•°æ®åº“è¿æ¥æˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            return False

    def disconnect_database(self):
        """æ–­å¼€æ•°æ®åº“è¿æ¥"""
        if self.data_operator:
            self.data_operator.disconnect_db()
        logger.info("æ•°æ®åº“è¿æ¥å·²å…³é—­")

    def get_yesterday_time_range(self):
        """
        è·å–æ˜¨å¤©çš„æ—¶é—´èŒƒå›´ï¼ˆç”¨äºæŸ¥è¯¢æ˜¨å¤©æ›´æ–°çš„è®¢å•ï¼‰

        Returns:
            tuple: (start_time, end_time) æ—¶é—´æˆ³
        """
        # è·å–æ˜¨å¤©æ—¥æœŸ
        yesterday = datetime.now() - timedelta(days=1)
        start_time = datetime(yesterday.year, yesterday.month, yesterday.day, 0, 0, 0)
        end_time = datetime(yesterday.year, yesterday.month, yesterday.day, 23, 59, 59)

        start_timestamp = int(start_time.timestamp())
        end_timestamp = int(end_time.timestamp())

        logger.info(f"æŸ¥è¯¢æ—¶é—´èŒƒå›´: {start_time} åˆ° {end_time}")
        return start_timestamp, end_timestamp

    def get_recent_days_time_range(self, days=1):
        """
        è·å–æœ€è¿‘Nå¤©çš„æ—¶é—´èŒƒå›´

        Args:
            days: æŸ¥è¯¢æœ€è¿‘å¤šå°‘å¤©

        Returns:
            tuple: (start_time, end_time) æ—¶é—´æˆ³
        """
        end_time = datetime.now()
        start_time = end_time - timedelta(days=days)

        start_timestamp = int(start_time.timestamp())
        end_timestamp = int(end_time.timestamp())

        logger.info(f"æŸ¥è¯¢æœ€è¿‘{days}å¤©æ—¶é—´èŒƒå›´: {start_time} åˆ° {end_time}")
        return start_timestamp, end_timestamp

    def fetch_updated_orders(self, days_to_check=1):
        """
        è·å–éœ€è¦æ›´æ–°çš„è®¢å•æ•°æ®
        Args:
            days_to_check: æ£€æŸ¥æœ€è¿‘å¤šå°‘å¤©çš„è®¢å•
        Returns:
            list: è®¢å•æ•°æ®åˆ—è¡¨
        """
        try:
            # è·å–æ—¶é—´èŒƒå›´
            start_time, end_time = self.get_recent_days_time_range(days_to_check)

            # æ„å»ºAPIè¯·æ±‚å‚æ•°
            api_path = "/pb/mp/order/v2/list"
            base_biz_body = {
                "start_time": start_time,
                "end_time": end_time,
                "date_type": "update_time",  # æŒ‰æ›´æ–°æ—¶é—´æŸ¥è¯¢
                "platform_code": [10024],  # æŒ‡å®šå¹³å°
            }

            logger.info("å¼€å§‹è·å–è®¢å•æ›´æ–°æ•°æ®...")
            total_processed = self.api_client.fetch_and_process_order_data_batch(
                api_path, base_biz_body, self.db_config, delay=1
            )

            logger.info(f"è®¢å•æ•°æ®è·å–å®Œæˆï¼Œå…±å¤„ç† {total_processed} æ¡è®°å½•")
            return total_processed > 0

        except Exception as e:
            logger.error(f"è·å–è®¢å•æ•°æ®å¤±è´¥: {e}")
            return False

    def update_store_info(self):
        """
        æ›´æ–°åº—é“ºä¿¡æ¯è¡¨
        Returns:
            bool: æ›´æ–°æ˜¯å¦æˆåŠŸ
        """
        try:
            logger.info("å¼€å§‹æ›´æ–°åº—é“ºä¿¡æ¯...")

            # è°ƒç”¨åº—é“ºä¿¡æ¯API
            success = self.api_client.getstoreList(self.db_config)

            if success:
                logger.info("âœ… åº—é“ºä¿¡æ¯æ›´æ–°æˆåŠŸ")
            else:
                logger.error("âŒ åº—é“ºä¿¡æ¯æ›´æ–°å¤±è´¥")

            return success

        except Exception as e:
            logger.error(f"æ›´æ–°åº—é“ºä¿¡æ¯å¤±è´¥: {e}")
            return False

    def update_warehouse_info(self):
        """
        æ›´æ–°ä»“åº“ä¿¡æ¯è¡¨
        Returns:
            bool: æ›´æ–°æ˜¯å¦æˆåŠŸ
        """
        try:
            logger.info("å¼€å§‹æ›´æ–°ä»“åº“ä¿¡æ¯...")

            # è°ƒç”¨ä»“åº“ä¿¡æ¯API
            self.api_client.getwarehouseList(self.db_config, type=3)

            logger.info("âœ… ä»“åº“ä¿¡æ¯æ›´æ–°å®Œæˆ")
            return True

        except Exception as e:
            logger.error(f"æ›´æ–°ä»“åº“ä¿¡æ¯å¤±è´¥: {e}")
            return False

    def update_inventory_info(self):
        """
        æ›´æ–°åº“å­˜ä¿¡æ¯è¡¨
        Returns:
            bool: æ›´æ–°æ˜¯å¦æˆåŠŸ
        """
        try:
            logger.info("å¼€å§‹æ›´æ–°åº“å­˜ä¿¡æ¯...")

            # è·å–æ‰€æœ‰ä»“åº“ID
            warehouse_ids = self.api_client.getwarehouseids(self.db_config)

            if not warehouse_ids:
                logger.warning("æœªè·å–åˆ°ä»“åº“IDï¼Œè·³è¿‡åº“å­˜æ›´æ–°")
                return False

            # å°†ä»“åº“IDåˆ—è¡¨è½¬æ¢ä¸ºé€—å·åˆ†éš”çš„å­—ç¬¦ä¸²
            wid_str = ",".join([str(wid) for wid in warehouse_ids])
            logger.info(f"è·å–åˆ° {len(warehouse_ids)} ä¸ªä»“åº“ï¼Œå¼€å§‹æ›´æ–°åº“å­˜...")

            # è°ƒç”¨åº“å­˜ä¿¡æ¯API
            success = self.api_client.getinvetoryList(self.db_config, str=wid_str)

            if success:
                logger.info("âœ… åº“å­˜ä¿¡æ¯æ›´æ–°æˆåŠŸ")
            else:
                logger.error("âŒ åº“å­˜ä¿¡æ¯æ›´æ–°å¤±è´¥")

            return success

        except Exception as e:
            logger.error(f"æ›´æ–°åº“å­˜ä¿¡æ¯å¤±è´¥: {e}")
            return False


    def validate_order_status_consistency(self):
        """
        éªŒè¯è®¢å•çŠ¶æ€ä¸€è‡´æ€§ï¼ˆå¯é€‰åŠŸèƒ½ï¼‰
        ç¡®ä¿ordersè¡¨å’Œplatform_infoè¡¨çš„order_statuså­—æ®µä¸€è‡´
        """
        try:
            if not self.data_operator or not self.data_operator.conn:
                logger.warning("æ•°æ®åº“æœªè¿æ¥ï¼Œè·³è¿‡ä¸€è‡´æ€§éªŒè¯")
                return True

            # æ£€æŸ¥ä¸¤ä¸ªè¡¨çš„è®¢å•çŠ¶æ€æ˜¯å¦ä¸€è‡´
            check_sql = """
            SELECT 
                COUNT(*) as total_orders,
                SUM(CASE WHEN o.order_status = p.order_status THEN 1 ELSE 0 END) as matching_orders
            FROM orders o
            INNER JOIN platform_info p ON o.global_order_no = p.global_order_no
            WHERE o.update_time >= DATE_SUB(NOW(), INTERVAL 7 DAY)
            """

            self.data_operator.cursor.execute(check_sql)
            result = self.data_operator.cursor.fetchone()
            if result and result[0] > 0:
                consistency_rate = (result[1] / result[0]) * 100
                logger.info(f"è®¢å•çŠ¶æ€ä¸€è‡´æ€§æ£€æŸ¥: {consistency_rate:.2f}% ({result[1]}/{result[0]})")
                if consistency_rate < 95:
                    logger.warning("è®¢å•çŠ¶æ€ä¸€è‡´æ€§è¾ƒä½ï¼Œå»ºè®®æ£€æŸ¥æ•°æ®åŒæ­¥é€»è¾‘")

            return True

        except Exception as e:
            logger.error(f"è®¢å•çŠ¶æ€ä¸€è‡´æ€§æ£€æŸ¥å¤±è´¥: {e}")
            return False

    def cleanup_old_data(self, days_to_keep=90):
        """
        æ¸…ç†æ—§æ•°æ®ï¼ˆå¯é€‰åŠŸèƒ½ï¼‰

        Args:
            days_to_keep: ä¿ç•™å¤šå°‘å¤©çš„æ•°æ®
        """
        try:
            if not self.data_operator or not self.data_operator.conn:
                return False

            # æ¸…ç†90å¤©å‰çš„è®¢å•æ•°æ®ï¼ˆæ ¹æ®ä¸šåŠ¡éœ€æ±‚è°ƒæ•´ï¼‰
            cleanup_sql = """
            DELETE FROM orders 
            WHERE update_time < DATE_SUB(NOW(), INTERVAL %s DAY)
            AND order_status IN ('TRADE_FINISHED', 'TRADE_CLOSED')
            """

            self.data_operator.cursor.execute(cleanup_sql, (days_to_keep,))
            deleted_rows = self.data_operator.cursor.rowcount

            if deleted_rows > 0:
                logger.info(f"æ¸…ç†äº† {deleted_rows} æ¡ {days_to_keep} å¤©å‰çš„å·²å®Œæˆ/å·²å…³é—­è®¢å•")
                self.data_operator.conn.commit()

            return True

        except Exception as e:
            logger.error(f"æ•°æ®æ¸…ç†å¤±è´¥: {e}")
            if self.data_operator.conn:
                self.data_operator.conn.rollback()
            return False

    def run_daily_update(self, days_to_check=1, enable_cleanup=False,
                         update_inventory=True, update_warehouse=True,
                         update_store=True, update_sales=True, sales_days_back=7,
                         rebuild_merge_table=True):
        """
        æ‰§è¡Œæ¯æ—¥æ›´æ–°ä»»åŠ¡ï¼ˆæ•´åˆé”€é‡æ•°æ®æ›´æ–°ï¼‰

        Args:
            days_to_check: æ£€æŸ¥æœ€è¿‘å¤šå°‘å¤©çš„è®¢å•
            enable_cleanup: æ˜¯å¦å¯ç”¨æ•°æ®æ¸…ç†
            update_inventory: æ˜¯å¦æ›´æ–°åº“å­˜ä¿¡æ¯
            update_warehouse: æ˜¯å¦æ›´æ–°ä»“åº“ä¿¡æ¯
            update_store: æ˜¯å¦æ›´æ–°åº—é“ºä¿¡æ¯
            update_sales: æ˜¯å¦æ›´æ–°é”€é‡æ•°æ®
            sales_days_back: é”€é‡æ•°æ®å›æº¯å¤©æ•°
            rebuild_merge_table: æ˜¯å¦é‡å»ºè®¢å•åˆå¹¶å®½è¡¨

        Returns:
            bool: ä»»åŠ¡æ‰§è¡Œæ˜¯å¦æˆåŠŸ
        """
        logger.info("=" * 60)
        logger.info("å¼€å§‹æ‰§è¡Œæ¯æ—¥æ•°æ®æ›´æ–°ä»»åŠ¡")
        logger.info("=" * 60)

        start_time = time.time()
        overall_success = True
        task_results = {}

        try:
            # 1. è¿æ¥æ•°æ®åº“
            if not self.connect_database():
                return False

            # 2. è·å–å¹¶æ›´æ–°è®¢å•æ•°æ®
            logger.info("å¼€å§‹æ›´æ–°è®¢å•æ•°æ®...")
            order_success = self.fetch_updated_orders(days_to_check)
            task_results["è®¢å•æ•°æ®"] = order_success
            if not order_success:
                logger.error("è®¢å•æ•°æ®æ›´æ–°å¤±è´¥")
                overall_success = False
            else:
                logger.info("âœ… è®¢å•æ•°æ®æ›´æ–°æˆåŠŸ")

            # 3. æ›´æ–°ä»“åº“ä¿¡æ¯
            if update_warehouse:
                logger.info("å¼€å§‹æ›´æ–°ä»“åº“ä¿¡æ¯...")
                warehouse_success = self.update_warehouse_info()
                task_results["ä»“åº“ä¿¡æ¯"] = warehouse_success
                if not warehouse_success:
                    logger.warning("ä»“åº“ä¿¡æ¯æ›´æ–°å¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œå…¶ä»–ä»»åŠ¡")
                    overall_success = False
                else:
                    logger.info("âœ… ä»“åº“ä¿¡æ¯æ›´æ–°æˆåŠŸ")
            else:
                logger.info("è·³è¿‡ä»“åº“ä¿¡æ¯æ›´æ–°")
                task_results["ä»“åº“ä¿¡æ¯"] = "è·³è¿‡"

            # 4. æ›´æ–°åº—é“ºä¿¡æ¯
            if update_store:
                logger.info("å¼€å§‹æ›´æ–°åº—é“ºä¿¡æ¯...")
                store_success = self.update_store_info()
                task_results["åº—é“ºä¿¡æ¯"] = store_success
                if not store_success:
                    logger.warning("åº—é“ºä¿¡æ¯æ›´æ–°å¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œå…¶ä»–ä»»åŠ¡")
                    overall_success = False
                else:
                    logger.info("âœ… åº—é“ºä¿¡æ¯æ›´æ–°æˆåŠŸ")
            else:
                logger.info("è·³è¿‡åº—é“ºä¿¡æ¯æ›´æ–°")
                task_results["åº—é“ºä¿¡æ¯"] = "è·³è¿‡"

            # 5. æ›´æ–°åº“å­˜ä¿¡æ¯ï¼ˆéœ€è¦å…ˆæœ‰ä»“åº“ä¿¡æ¯ï¼‰
            if update_inventory:
                logger.info("å¼€å§‹æ›´æ–°åº“å­˜ä¿¡æ¯...")
                inventory_success = self.update_inventory_info()
                task_results["åº“å­˜ä¿¡æ¯"] = inventory_success
                if not inventory_success:
                    logger.warning("åº“å­˜ä¿¡æ¯æ›´æ–°å¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œå…¶ä»–ä»»åŠ¡")
                    overall_success = False
                else:
                    logger.info("âœ… åº“å­˜ä¿¡æ¯æ›´æ–°æˆåŠŸ")
            else:
                logger.info("è·³è¿‡åº“å­˜ä¿¡æ¯æ›´æ–°")
                task_results["åº“å­˜ä¿¡æ¯"] = "è·³è¿‡"

            # 6. æ›´æ–°é”€é‡æ•°æ®
            if update_sales:
                logger.info("å¼€å§‹æ›´æ–°é”€é‡æ•°æ®...")
                sales_success = self._update_daily_sales(sales_days_back, enable_cleanup)
                task_results["é”€é‡æ•°æ®"] = sales_success
                if not sales_success:
                    logger.warning("é”€é‡æ•°æ®æ›´æ–°å¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œå…¶ä»–ä»»åŠ¡")
                    overall_success = False
                else:
                    logger.info("âœ… é”€é‡æ•°æ®æ›´æ–°æˆåŠŸ")
            else:
                logger.info("è·³è¿‡é”€é‡æ•°æ®æ›´æ–°")
                task_results["é”€é‡æ•°æ®"] = "è·³è¿‡"

            # 7. é‡å»ºè®¢å•åˆå¹¶å®½è¡¨ï¼ˆä¾›å‰ç«¯å±•ç¤ºï¼‰
            if rebuild_merge_table:
                logger.info("å¼€å§‹é‡å»ºè®¢å•åˆå¹¶å®½è¡¨...")
                merge_success = self.rebuild_orders_merge_table()
                task_results["åˆå¹¶å®½è¡¨"] = merge_success
                if not merge_success:
                    logger.warning("è®¢å•åˆå¹¶å®½è¡¨é‡å»ºå¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œå…¶ä»–ä»»åŠ¡")
                    overall_success = False
                else:
                    logger.info("âœ… è®¢å•åˆå¹¶å®½è¡¨é‡å»ºæˆåŠŸ")
            else:
                logger.info("è·³è¿‡è®¢å•åˆå¹¶å®½è¡¨é‡å»º")
                task_results["åˆå¹¶å®½è¡¨"] = "è·³è¿‡"

            # 8. éªŒè¯æ•°æ®ä¸€è‡´æ€§ï¼ˆå¯é€‰ï¼‰
            logger.info("å¼€å§‹éªŒè¯æ•°æ®ä¸€è‡´æ€§...")
            consistency_success = self.validate_order_status_consistency()
            task_results["æ•°æ®ä¸€è‡´æ€§"] = consistency_success
            if not consistency_success:
                logger.warning("æ•°æ®ä¸€è‡´æ€§éªŒè¯å¤±è´¥")
            else:
                logger.info("âœ… æ•°æ®ä¸€è‡´æ€§éªŒè¯å®Œæˆ")

            # 9. æ¸…ç†æ—§æ•°æ®
            if enable_cleanup:
                logger.info("å¼€å§‹æ¸…ç†æ—§æ•°æ®...")
                cleanup_success = self.cleanup_old_data()
                task_results["æ•°æ®æ¸…ç†"] = cleanup_success
                if not cleanup_success:
                    logger.warning("æ•°æ®æ¸…ç†å¤±è´¥")
                else:
                    logger.info("âœ… æ•°æ®æ¸…ç†å®Œæˆ")
            else:
                logger.info("è·³è¿‡æ•°æ®æ¸…ç†")
                task_results["æ•°æ®æ¸…ç†"] = "è·³è¿‡"

            # 10. è®¡ç®—æ‰§è¡Œæ—¶é—´å¹¶ç”ŸæˆæŠ¥å‘Š
            execution_time = time.time() - start_time
            self._generate_update_report(task_results, execution_time, overall_success)

        except Exception as e:
            logger.error(f"æ¯æ—¥æ›´æ–°ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
            overall_success = False
            import traceback
            logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")

        finally:
            # ç¡®ä¿æ•°æ®åº“è¿æ¥è¢«å…³é—­
            self.disconnect_database()

        return overall_success

    def _update_daily_sales(self, days_back=7, enable_cleanup=False):
        """
        å†…éƒ¨æ–¹æ³•ï¼šæ›´æ–°æ¯æ—¥é”€é‡æ•°æ®ï¼ˆä¸åŒ…å«æ•°æ®åº“è¿æ¥ç®¡ç†ï¼‰

        Args:
            days_back: è·å–æœ€è¿‘å¤šå°‘å¤©çš„æ•°æ®
            enable_cleanup: æ˜¯å¦å¯ç”¨æ•°æ®æ¸…ç†

        Returns:
            bool: æ›´æ–°æ˜¯å¦æˆåŠŸ
        """
        try:
            overall_success = True

            # æ›´æ–°é”€é‡ç»Ÿè®¡æ•°æ®ï¼ˆæŒ‰ä¸åŒç»´åº¦åˆ†åˆ«æ›´æ–°ï¼‰
            update_tasks = [
                {"name": "SKUç»´åº¦é”€é‡", "data_type": "4"},
                {"name": "åº—é“ºç»´åº¦é”€é‡", "data_type": "6"},
                {"name": "ASINç»´åº¦é”€é‡", "data_type": "1"}
            ]

            for task in update_tasks:
                logger.info(f"å¼€å§‹æ›´æ–° {task['name']} æ•°æ®...")

                task_success = self.update_sales_statistics(
                    days_back=days_back,
                    result_type="1",  # é”€é‡
                    date_unit="4",  # æŒ‰æ—¥ç»Ÿè®¡
                    data_type=task['data_type']
                )

                if not task_success:
                    logger.warning(f"{task['name']} æ›´æ–°å¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œå…¶ä»–ä»»åŠ¡")
                    overall_success = False
                else:
                    logger.info(f"âœ… {task['name']} æ›´æ–°å®Œæˆ")

                # ä»»åŠ¡é—´çŸ­æš‚å»¶è¿Ÿï¼Œé¿å…APIé™æµ
                time.sleep(2)

            # å¯é€‰ï¼šæ¸…ç†æ—§æ•°æ®
            if enable_cleanup:
                cleanup_success = self.cleanup_old_sales_data(days_to_keep=90)
                if not cleanup_success:
                    logger.warning("é”€é‡æ•°æ®æ¸…ç†å¤±è´¥")

            return overall_success

        except Exception as e:
            logger.error(f"é”€é‡æ•°æ®æ›´æ–°å¤±è´¥: {e}")
            return False

    def _generate_update_report(self, task_results, execution_time, overall_success):
        """
        ç”Ÿæˆæ›´æ–°ä»»åŠ¡æŠ¥å‘Š

        Args:
            task_results: å„ä»»åŠ¡æ‰§è¡Œç»“æœå­—å…¸
            execution_time: æ€»æ‰§è¡Œæ—¶é—´
            overall_success: æ•´ä½“æ˜¯å¦æˆåŠŸ
        """
        logger.info("=" * 60)
        logger.info("æ¯æ—¥æ•°æ®æ›´æ–°ä»»åŠ¡æŠ¥å‘Š")
        logger.info("=" * 60)

        success_count = 0
        total_count = 0

        for task_name, result in task_results.items():
            total_count += 1
            status_icon = "âœ…" if result is True else "âš ï¸" if result == "è·³è¿‡" else "âŒ"
            status_text = "æˆåŠŸ" if result is True else "è·³è¿‡" if result == "è·³è¿‡" else "å¤±è´¥"
            logger.info(f"{status_icon} {task_name}: {status_text}")

            if result is True:
                success_count += 1

        success_rate = (success_count / total_count) * 100 if total_count > 0 else 0

        logger.info("-" * 40)
        logger.info(f"ä»»åŠ¡å®Œæˆæƒ…å†µ: {success_count}/{total_count} ({success_rate:.1f}%)")
        logger.info(f"æ€»æ‰§è¡Œæ—¶é—´: {execution_time:.2f} ç§’")

        if overall_success:
            logger.info("ğŸ‰ æ‰€æœ‰å…³é”®ä»»åŠ¡æ‰§è¡ŒæˆåŠŸ")
        else:
            logger.info("âš ï¸  éƒ¨åˆ†ä»»åŠ¡æ‰§è¡Œå¤±è´¥ï¼Œä½†éå…³é”®ä»»åŠ¡ä¸å½±å“æ•´ä½“æµç¨‹")

        logger.info("=" * 60)
    def update_sales_statistics(self, days_back=7, result_type="1", date_unit="4", data_type="4", sids=None):
        """
        æ›´æ–°é”€é‡ç»Ÿè®¡æ•°æ®

        Args:
            days_back: è·å–æœ€è¿‘å¤šå°‘å¤©çš„æ•°æ®ï¼ˆé»˜è®¤7å¤©ï¼‰
            result_type: æ±‡æ€»ç±»å‹ 1é”€é‡ 2è®¢å•é‡ 3é”€å”®é¢
            date_unit: ç»Ÿè®¡æ—¶é—´æŒ‡æ ‡ 1å¹´ 2æœˆ 3å‘¨ 4æ—¥
            data_type: ç»Ÿè®¡æ•°æ®ç»´åº¦ 1ASIN 2çˆ¶ä½“ 3MSKU 4SKU 5SPU 6åº—é“º
            sids: åº—é“ºIDåˆ—è¡¨ï¼Œå¤šä¸ªä½¿ç”¨è‹±æ–‡é€—å·åˆ†éš”

        Returns:
            bool: æ›´æ–°æ˜¯å¦æˆåŠŸ
        """
        try:
            from datetime import datetime, timedelta

            # è®¡ç®—æ—¥æœŸèŒƒå›´ï¼ˆç¡®ä¿ä¸è¶…è¿‡90å¤©é™åˆ¶ï¼‰
            days_back = min(days_back, 90)  # APIé™åˆ¶æœ€å¤§90å¤©
            end_date = datetime.now().date()
            start_date = end_date - timedelta(days=days_back)

            start_date_str = start_date.strftime("%Y-%m-%d")
            end_date_str = end_date.strftime("%Y-%m-%d")

            print(f"å¼€å§‹æ›´æ–°é”€é‡ç»Ÿè®¡æ•°æ®ï¼Œæ—¶é—´èŒƒå›´: {start_date_str} åˆ° {end_date_str}")
            print(f"ç»Ÿè®¡å‚æ•° - æ±‡æ€»ç±»å‹: {result_type}, æ—¶é—´å•ä½: {date_unit}, æ•°æ®ç»´åº¦: {data_type}")

            if sids:
                print(f"æŒ‡å®šåº—é“ºID: {sids}")

            # è°ƒç”¨é”€é‡æ•°æ®è·å–æ–¹æ³•
            success = self.api_client.get_sales_by_date_range(
                db_config=self.db_config,
                start_date=start_date_str,
                end_date=end_date_str,
                result_type=result_type,
                date_unit=date_unit,
                data_type=data_type,
                sids=sids
            )

            if success:
                print("é”€é‡ç»Ÿè®¡æ•°æ®æ›´æ–°æˆåŠŸ")
                # è®°å½•æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                self._log_sales_update_summary(start_date_str, end_date_str)
            else:
                print("é”€é‡ç»Ÿè®¡æ•°æ®æ›´æ–°å¤±è´¥")

            return success

        except Exception as e:
            print(f"æ›´æ–°é”€é‡ç»Ÿè®¡æ•°æ®å¤±è´¥: {e}")
            import traceback
            print(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            return False

    def _log_sales_update_summary(self, start_date, end_date):
        """
        è®°å½•é”€é‡æ•°æ®æ›´æ–°æ‘˜è¦ä¿¡æ¯ï¼ˆé€‚é…sales_codeï¼‰
        """
        try:
            if not self.data_operator or not self.data_operator.conn:
                self.connect_database()

            # æŸ¥è¯¢æœ¬æ¬¡æ›´æ–°çš„æ•°æ®ç»Ÿè®¡
            summary_sql = """
            SELECT 
                COUNT(*) as total_records,
                COUNT(DISTINCT sales_code) as sales_code,
                SUM(volume_total) as total_volume,
                AVG(volume_total) as avg_volume,
                MIN(create_time) as earliest_record,
                MAX(create_time) as latest_record
            FROM sales_info 
            WHERE create_time >= DATE_SUB(NOW(), INTERVAL 1 HOUR)
            AND create_time <= NOW()
            """

            self.data_operator.cursor.execute(summary_sql)
            result = self.data_operator.cursor.fetchone()

            if result and result[0] > 0:
                print(f"é”€é‡æ›´æ–°æ‘˜è¦ - æ—¶é—´æ®µ: {start_date} è‡³ {end_date}")
                print(f"  æ–°å¢è®°å½•æ•°: {result[0]} æ¡")
                print(f"  å”¯ä¸€SKUæ•°é‡: {result[1]} ä¸ª")
                print(f"  æ€»é”€é‡/é”€å”®é¢: {result[2]:.2f}")
                print(f"  å¹³å‡é”€é‡/é”€å”®é¢: {result[3]:.2f}")
                print(f"  æœ€æ—©è®°å½•æ—¶é—´: {result[4]}")
                print(f"  æœ€æ™šè®°å½•æ—¶é—´: {result[5]}")
            else:
                print("æœªæ‰¾åˆ°æœ¬æ¬¡æ›´æ–°çš„é”€é‡è®°å½•")

        except Exception as e:
            print(f"ç”Ÿæˆé”€é‡æ›´æ–°æ‘˜è¦å¤±è´¥: {e}")

    def cleanup_old_sales_data(self, days_to_keep=90):
        """
        æ¸…ç†æ—§çš„é”€é‡æ•°æ®
        """
        try:
            if not self.data_operator or not self.data_operator.conn:
                self.connect_database()

            # å…ˆç»Ÿè®¡è¦åˆ é™¤çš„æ•°æ®é‡
            count_sql = "SELECT COUNT(*) FROM sales_info WHERE create_time < DATE_SUB(NOW(), INTERVAL %s DAY)"
            self.data_operator.cursor.execute(count_sql, (days_to_keep,))
            count_result = self.data_operator.cursor.fetchone()

            if count_result and count_result[0] > 0:
                print(f"å‡†å¤‡æ¸…ç† {count_result[0]} æ¡ {days_to_keep} å¤©å‰çš„é”€é‡æ•°æ®")

                # æ‰§è¡Œåˆ é™¤
                delete_sql = "DELETE FROM sales_info WHERE create_time < DATE_SUB(NOW(), INTERVAL %s DAY)"
                self.data_operator.cursor.execute(delete_sql, (days_to_keep,))
                deleted_rows = self.data_operator.cursor.rowcount

                self.data_operator.conn.commit()
                print(f"æˆåŠŸæ¸…ç† {deleted_rows} æ¡æ—§é”€é‡æ•°æ®")

                # ä¼˜åŒ–è¡¨ç©ºé—´
                optimize_sql = "OPTIMIZE TABLE sales_info"
                self.data_operator.cursor.execute(optimize_sql)
                print("è¡¨ç©ºé—´ä¼˜åŒ–å®Œæˆ")

                return True
            else:
                print(f"æ²¡æœ‰éœ€è¦æ¸…ç†çš„æ—§é”€é‡æ•°æ®ï¼ˆä¿ç•™ {days_to_keep} å¤©ï¼‰")
                return True

        except Exception as e:
            print(f"æ¸…ç†æ—§é”€é‡æ•°æ®å¤±è´¥: {e}")
            if self.data_operator.conn:
                self.data_operator.conn.rollback()
            return False

    def rebuild_orders_merge_table(self):
        """
        é‡å»ºè®¢å•åˆå¹¶å®½è¡¨ orders_merge
        å°†è®¢å•ã€ç‰©æµã€å•†å“å’Œåº—é“ºä¿¡æ¯è”åˆä¸ºä¸€ä¸ªå®½è¡¨ä¾›å‰ç«¯å±•ç¤º
        """
        try:
            print("å¼€å§‹é‡å»ºè®¢å•åˆå¹¶å®½è¡¨...")

            if not self.data_operator or not self.data_operator.conn:
                self.connect_database()

            # é‡å»ºåˆå¹¶è¡¨çš„SQLè¯­å¥
            sql = """
            DROP TABLE IF EXISTS orders_merge;

            CREATE TABLE orders_merge AS
            SELECT 
                o.global_order_no,
                o.reference_no,
                o.store_id,
                o.order_from_name,
                o.delivery_type,
                o.split_type,
                o.order_status,
                -- å°†æ—¶é—´å­—æ®µæ”¹ä¸ºDATETIMEç±»å‹
                CASE 
                    WHEN o.global_purchase_time IS NOT NULL AND o.global_purchase_time != 0 
                    THEN FROM_UNIXTIME(o.global_purchase_time, '%Y-%m-%d %H:%i:%s')
                    ELSE NULL 
                END AS global_purchase_time,
                
                CASE 
                    WHEN o.global_payment_time IS NOT NULL AND o.global_payment_time != 0 
                    THEN FROM_UNIXTIME(o.global_payment_time, '%Y-%m-%d %H:%i:%s')
                    ELSE NULL 
                END AS global_payment_time,
                
                CASE 
                    WHEN o.global_review_time IS NOT NULL AND o.global_review_time != 0 
                    THEN FROM_UNIXTIME(o.global_review_time, '%Y-%m-%d %H:%i:%s')
                    ELSE NULL 
                END AS global_review_time,
                
                CASE 
                    WHEN o.global_distribution_time IS NOT NULL AND o.global_distribution_time != 0 
                    THEN FROM_UNIXTIME(o.global_distribution_time, '%Y-%m-%d %H:%i:%s')
                    ELSE NULL 
                END AS global_distribution_time,
                
                CASE 
                    WHEN o.global_print_time IS NOT NULL AND o.global_print_time != 0 
                    THEN FROM_UNIXTIME(o.global_print_time, '%Y-%m-%d %H:%i:%s')
                    ELSE NULL 
                END AS global_print_time,
                
                CASE 
                    WHEN o.global_mark_time IS NOT NULL AND o.global_mark_time != 0 
                    THEN FROM_UNIXTIME(o.global_mark_time, '%Y-%m-%d %H:%i:%s')
                    ELSE NULL 
                END AS global_mark_time,
                
                CASE 
                    WHEN o.global_delivery_time IS NOT NULL AND o.global_delivery_time != 0 
                    THEN FROM_UNIXTIME(o.global_delivery_time, '%Y-%m-%d %H:%i:%s')
                    ELSE NULL 
                END AS global_delivery_time,
                
                o.amount_currency,
                
                CASE 
                    WHEN o.global_latest_ship_time IS NOT NULL AND o.global_latest_ship_time != 0 
                    THEN FROM_UNIXTIME(o.global_latest_ship_time, '%Y-%m-%d %H:%i:%s')
                    ELSE NULL 
                END AS global_latest_ship_time,
                
                CASE 
                    WHEN o.global_cancel_time IS NOT NULL AND o.global_cancel_time != 0 
                    THEN FROM_UNIXTIME(o.global_cancel_time, '%Y-%m-%d %H:%i:%s')
                    ELSE NULL 
                END AS global_cancel_time,
                
                CASE 
                    WHEN o.update_time IS NOT NULL AND o.update_time != 0 
                    THEN FROM_UNIXTIME(o.update_time, '%Y-%m-%d %H:%i:%s')
                    ELSE NULL 
                END AS update_time,
                
                o.order_tag,
                o.pending_order_tag,
                o.exception_order_tag,
                o.wid,
                o.warehouse_name,
                o.original_global_order_no,
                o.supplier_id,
                o.is_delete,
                o.order_custom_fields,
                
                CASE 
                    WHEN o.global_create_time IS NOT NULL AND o.global_create_time != 0 
                    THEN FROM_UNIXTIME(o.global_create_time, '%Y-%m-%d %H:%i:%s')
                    ELSE NULL 
                END AS global_create_time,
                
                l.logistics_type_id,
                l.logistics_type_name,
                l.logistics_provider_id,
                l.logistics_provider_name,
                l.actual_carrier,
                l.waybill_no,
                l.pre_weight,
                l.pre_fee_weight,
                l.pre_fee_weight_unit,
                l.pre_pkg_length,
                l.pre_pkg_height,
                l.pre_pkg_width,
                l.weight,
                l.pkg_fee_weight,
                l.pkg_fee_weight_unit,
                l.pkg_length,
                l.pkg_width,
                l.pkg_height,
                l.weight_unit,
                l.pkg_size_unit,
                l.cost_currency_code,
                
                CASE 
                    WHEN l.pre_cost_amount IS NOT NULL
                    THEN CAST(REPLACE(REPLACE(l.pre_cost_amount, '-ï¿¥', ''), 'ï¿¥', '') AS DECIMAL(10,2))
                    ELSE NULL 
                END AS pre_cost_amount,
                
                l.cost_amount,
                
                CASE 
                    WHEN l.logistics_time IS NOT NULL AND l.logistics_time != 0 
                    THEN FROM_UNIXTIME(l.logistics_time, '%Y-%m-%d %H:%i:%s')
                    ELSE NULL 
                END AS logistics_time,
                
                l.tracking_no,
                l.mark_no,
                i.global_item_no,
                i.item_id,
                i.platform_order_no,
                i.order_item_no,
                i.item_from_name,
                i.msku,
                i.local_sku,
                i.product_no,
                i.local_product_name,
                i.is_bundled,
                i.title,
                i.variant_attr,
                i.unit_price_amount,
                i.item_price_amount,
                i.quantity,
                i.platform_status,
                i.item_type,
                i.stock_cost_amount,
                i.wms_outbound_cost_amount,
                i.stock_deduct_id,
                i.stock_deduct_name,
                i.cg_price_amount,
                i.shipping_amount,
                i.wms_shipping_price_amount,
                i.customer_shipping_amount,
                i.discount_amount,
                i.customer_tip_amount,
                i.tax_amount,
                i.sales_revenue_amount,
                i.transaction_fee_amount,
                i.other_amount,
                i.customized_url,
                i.platform_subsidy_amount,
                i.cod_amount,
                i.gift_wrap_amount,
                i.platform_tax_amount,
                i.points_granted_amount,
                i.other_fee,
                
                CASE 
                    WHEN i.delivery_time IS NOT NULL AND i.delivery_time != 0 
                    THEN FROM_UNIXTIME(i.delivery_time, '%Y-%m-%d %H:%i:%s')
                    ELSE NULL 
                END AS delivery_time,
                
                i.source_name,
                i.data_json,
                i.item_custom_fields,
                s.sid AS store_sid,
                s.store_name AS store_full_name,
                s.platform_code AS store_platform_code,
                s.platform_name AS store_platform_name,
                s.currency AS store_currency,
                s.is_sync AS store_is_sync,
                s.status AS store_status,
                s.country_code AS store_country_code
            FROM orders o
            LEFT JOIN logistics_info l ON o.global_order_no = l.global_order_no
            LEFT JOIN item_info i ON o.global_order_no = i.global_order_no
            LEFT JOIN store_info s ON o.store_id = s.store_id;

            ALTER TABLE orders_merge ADD PRIMARY KEY (global_item_no);

            -- æ·»åŠ ç´¢å¼•ä»¥æé«˜æŸ¥è¯¢æ€§èƒ½
            CREATE INDEX idx_orders_merge_global_item_no ON orders_merge(global_item_no);
            CREATE INDEX idx_orders_merge_global_order_no ON orders_merge(global_order_no);
            CREATE INDEX idx_orders_merge_store_id ON orders_merge(store_id);
            """

            # æ‰§è¡ŒSQLè¯­å¥
            statements = [stmt.strip() for stmt in sql.split(';') if stmt.strip()]

            for statement in statements:
                try:
                    self.data_operator.cursor.execute(statement)
                    print(f"æ‰§è¡ŒSQLæˆåŠŸ: {statement[:100]}...")
                except Exception as e:
                    print(f"æ‰§è¡ŒSQLå¤±è´¥: {e}")
                    print(f"å¤±è´¥è¯­å¥: {statement}")
                    # ç»§ç»­æ‰§è¡Œå…¶ä»–è¯­å¥ï¼Œä¸ä¸­æ–­æ•´ä¸ªæµç¨‹

            self.data_operator.conn.commit()
            print("è®¢å•åˆå¹¶å®½è¡¨é‡å»ºæˆåŠŸ")
            return True

        except Exception as e:
            print(f"é‡å»ºè®¢å•åˆå¹¶å®½è¡¨å¤±è´¥: {e}")
            if self.data_operator.conn:
                self.data_operator.conn.rollback()
            return False



def main():
    try:
        logger.info("=" * 60)
        logger.info("æ¯æ—¥æ•°æ®æ›´æ–°ç³»ç»Ÿå¯åŠ¨")
        logger.info("=" * 60)

        # åŠ è½½é…ç½®
        config = load_config_from_env()

        # åˆ›å»ºæ›´æ–°å™¨å®ä¾‹
        updater = DailyOrderUpdater(
            app_id=config['app_id'],
            app_secret=config['app_secret'],
            db_config=config['db_config']
        )

        # æ‰§è¡Œæ•´åˆåçš„æ¯æ—¥æ›´æ–°ä»»åŠ¡
        success = updater.run_daily_update(
            days_to_check=1,           # æ£€æŸ¥æœ€è¿‘1å¤©çš„è®¢å•
            enable_cleanup=True,      # æ˜¯å¦å¯ç”¨æ•°æ®æ¸…ç†
            update_inventory=True,     # æ›´æ–°åº“å­˜ä¿¡æ¯
            update_warehouse=True,     # æ›´æ–°ä»“åº“ä¿¡æ¯
            update_store=True,         # æ›´æ–°åº—é“ºä¿¡æ¯
            update_sales=True,         # æ›´æ–°é”€é‡æ•°æ®
            sales_days_back=7,         # é”€é‡æ•°æ®å›æº¯7å¤©
            rebuild_merge_table=True   # é‡å»ºè®¢å•åˆå¹¶å®½è¡¨
        )

        if success:
            logger.info("âœ… æ¯æ—¥æ•°æ®æ›´æ–°ä»»åŠ¡æ‰§è¡ŒæˆåŠŸ")
            sys.exit(0)
        else:
            logger.warning("âš ï¸ éƒ¨åˆ†æ•°æ®æ›´æ–°ä»»åŠ¡æ‰§è¡Œå¤±è´¥")
            sys.exit(1)

    except Exception as e:
        logger.error(f"ğŸ’¥ ç³»ç»Ÿæ‰§è¡Œå‡ºç°æœªé¢„æœŸé”™è¯¯: {e}")
        import traceback
        logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        sys.exit(1)


if __name__ == "__main__":
    main()
